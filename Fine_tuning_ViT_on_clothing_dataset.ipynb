{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "H9hWomDZ6PBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import io\n",
        "zf = zipfile.ZipFile(io.BytesIO(uploaded['clothing-dataset.zip']), \"r\")\n",
        "zf.extractall()"
      ],
      "metadata": {
        "id": "s31WfuAe6QAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import random"
      ],
      "metadata": {
        "id": "FCu3OEwu6W0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('./clothing-dataset/images.csv').set_index('image')\n",
        "data.tail()"
      ],
      "metadata": {
        "id": "vgYoPRCR6YsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_labels = pd.DataFrame(data.groupby('label').size().reset_index().sort_values(0,ascending = False)[:11]['label'])\n",
        "top_labels = top_labels[top_labels.label!='Not sure']\n",
        "top_labels_list = sorted(list(top_labels['label']))\n",
        "top_labels['label_num'] = top_labels['label'].apply(lambda x: top_labels_list.index(x))\n",
        "top_labels"
      ],
      "metadata": {
        "id": "v2lqtvZb6dnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_filtered = pd.merge(data.reset_index(), top_labels).set_index('image')\n",
        "data_filtered['label_str'] = data_filtered['label']\n",
        "data_filtered['label'] = data_filtered['label_num']"
      ],
      "metadata": {
        "id": "NSJ0CkOE9CBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_data = []\n",
        "for i, item in enumerate(os.listdir( './clothing-dataset/images' )):\n",
        "    path = os.path.join('./clothing-dataset/images', item) \n",
        "    img = image.load_img(path, target_size=(32, 32))\n",
        "    \n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    images = np.vstack([x])[0].tolist()\n",
        "\n",
        "    try:\n",
        "        label = data_filtered.loc[item[:-4],'label']\n",
        "        labeled_data.append({'img':images, 'label':label, 'index':item[:-4]})\n",
        "    except:\n",
        "        label = 'no_data'"
      ],
      "metadata": {
        "id": "YzLrmY6f9LvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind = data_filtered.index.tolist()\n",
        "random.shuffle(ind)"
      ],
      "metadata": {
        "id": "Z6VdPaOI9ZR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(data_filtered)\n",
        "p_train = 0.6\n",
        "p_val = 0.2\n",
        "n_train = int(p_train*n)\n",
        "n_val = int(p_val*n)\n",
        "train_ind = ind[:n_train]\n",
        "val_ind = ind[n_train:(n_train+n_val)]\n",
        "test_ind = ind[(n_train+n_val):]"
      ],
      "metadata": {
        "id": "_e-cwHYT9cMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img = []\n",
        "val_img = []\n",
        "test_img = []\n",
        "train_label = []\n",
        "val_label = []\n",
        "test_label = []\n",
        "test_ids = []\n",
        "\n",
        "for img in labeled_data:\n",
        "    if img['index'] in train_ind:\n",
        "        train_img.append(img['img'])\n",
        "        train_label.append(img['label'])\n",
        "    elif img['index'] in val_ind:\n",
        "        val_img.append(img['img'])\n",
        "        val_label.append(img['label'])\n",
        "    elif img['index'] in test_ind:\n",
        "        test_img.append(img['img'])\n",
        "        test_label.append(img['label'])\n",
        "        test_ids.append(img['index'])"
      ],
      "metadata": {
        "id": "mUIEoaNp9dCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --quiet"
      ],
      "metadata": {
        "id": "ccXlZzAC9giY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "O5vPwCwH9i7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = Dataset.from_dict({'img':train_img,'label':train_label})\n",
        "val_ds = Dataset.from_dict({'img':val_img,'label':val_label})\n",
        "test_ds = Dataset.from_dict({'img':test_img,'label':test_label})"
      ],
      "metadata": {
        "id": "yRWuV2DZ9ork"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTFeatureExtractor\n",
        "\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')"
      ],
      "metadata": {
        "id": "zqR6IyTu9r0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(examples):\n",
        "    # get batch of images\n",
        "    images = examples['img']\n",
        "    # convert to list of NumPy arrays of shape (C, H, W)\n",
        "    images = [np.array(image, dtype=np.uint8) for image in images]\n",
        "    images = [np.moveaxis(image, source=-1, destination=0) for image in images]\n",
        "    # preprocess and add pixel_values\n",
        "    inputs = feature_extractor(images=images)\n",
        "    examples['pixel_values'] = inputs['pixel_values']\n",
        "\n",
        "    return examples"
      ],
      "metadata": {
        "id": "J4rWP74s9xHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Features, ClassLabel, Array3D\n",
        "\n",
        "# we need to define the features ourselves as both the img and pixel_values have a 3D shape \n",
        "features = Features({\n",
        "    'label': ClassLabel(names = top_labels_list),\n",
        "    'img': Array3D(dtype=\"int64\", shape=(3,32,32)),\n",
        "    'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
        "})\n",
        "\n",
        "preprocessed_train_ds = train_ds.map(preprocess_images, batched=True, features=features)\n",
        "preprocessed_val_ds = val_ds.map(preprocess_images, batched=True, features=features)\n",
        "preprocessed_test_ds = test_ds.map(preprocess_images, batched=True, features=features)"
      ],
      "metadata": {
        "id": "XHIRBTj391er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import torch.nn as nn\n",
        "\n",
        "class ViTForImageClassification(nn.Module):\n",
        "    def __init__(self, num_labels=10, vector_length=1000):\n",
        "        super(ViTForImageClassification, self).__init__()\n",
        "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.last_layer = nn.Linear(self.vit.config.hidden_size, num_labels)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "    def forward(self, pixel_values, labels):\n",
        "        outputs = self.vit(pixel_values=pixel_values)\n",
        "        output = self.dropout(outputs.last_hidden_state[:,0])\n",
        "        logits = self.last_layer(output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "          loss_fct = nn.CrossEntropyLoss()\n",
        "          loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )"
      ],
      "metadata": {
        "id": "Mkey6vKr95Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "metric_name = \"accuracy\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"test-clothing\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=10,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=metric_name,\n",
        "    logging_dir='logs',\n",
        ")"
      ],
      "metadata": {
        "id": "NCkSYGiV-LGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import default_data_collator\n",
        "\n",
        "data_collator = default_data_collator"
      ],
      "metadata": {
        "id": "FbCUKdrF-PeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViTForImageClassification()"
      ],
      "metadata": {
        "id": "wNntsk3S-QdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "import numpy as np\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "tXX4FVgG-T0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=preprocessed_train_ds,\n",
        "    eval_dataset=preprocessed_val_ds,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "0ZAHPGrd-ae_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "bbfd_-Gx-ds5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveOutput:\n",
        "    def __init__(self):\n",
        "        self.outputs = []\n",
        "        \n",
        "    def __call__(self, module, module_in, module_out):\n",
        "        self.outputs.append(module_in)\n",
        "        \n",
        "    def clear(self):\n",
        "        self.outputs = []\n",
        "        \n",
        "save_output = SaveOutput()\n",
        "\n",
        "hook_handles = []\n",
        "\n",
        "for layer in model.modules():\n",
        "    if str(layer) == 'Linear(in_features=768, out_features=10, bias=True)':\n",
        "        handle = layer.register_forward_hook(save_output)\n",
        "        hook_handles.append(handle)\n",
        "\n",
        "len(save_output.outputs)"
      ],
      "metadata": {
        "id": "wZ4GSelA-eqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = trainer.predict(preprocessed_test_ds)"
      ],
      "metadata": {
        "id": "BxgJOuSS-ns3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.metrics)"
      ],
      "metadata": {
        "id": "CSHYI7z6-qzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_vectors = save_output.outputs\n",
        "vectors_first_in = {}\n",
        "data_img_ids = test_ids\n",
        "batch_size=4\n",
        "for i in range(0,len(data_img_ids)):\n",
        "    first_index = i // batch_size\n",
        "    second_index = i % batch_size\n",
        "    vectors_first_in[data_img_ids[i]]=outputs_vectors[first_index][0][second_index].tolist()"
      ],
      "metadata": {
        "id": "3MJyNJ5U-sIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('vectors_test', 'w') as fp:\n",
        "    json.dump(vectors_first_out, fp)"
      ],
      "metadata": {
        "id": "DkquVMhe-zDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('vectors_test.json') "
      ],
      "metadata": {
        "id": "McbIvxwv-4Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.save(model.state_dict(), '/content/model')\n",
        "files.download('/content/model') "
      ],
      "metadata": {
        "id": "4tDnFP3A-8qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViTForImageClassification(nn.Module):\n",
        "    def __init__(self, num_labels=10, vector_length=1000):\n",
        "        super(ViTForImageClassification, self).__init__()\n",
        "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.pre_last_layer = nn.Linear(self.vit.config.hidden_size, vector_length)\n",
        "        self.last_layer = nn.Linear(vector_length, num_labels)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "    def forward(self, pixel_values, labels):\n",
        "        outputs = self.vit(pixel_values=pixel_values)\n",
        "        output = self.dropout(outputs.last_hidden_state[:,0])\n",
        "        pre_last_output = self.pre_last_layer(output)\n",
        "        logits = self.last_layer(pre_last_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "          loss_fct = nn.CrossEntropyLoss()\n",
        "          loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions)"
      ],
      "metadata": {
        "id": "XxFZx0AZ_Ai0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pretrained = ViTForImageClassification()"
      ],
      "metadata": {
        "id": "FMIyOeec_C-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import spatial"
      ],
      "metadata": {
        "id": "zzULqswT_SRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def changed_weight(layer):\n",
        "    model_weights = [] \n",
        "    for name, param in model.named_parameters():\n",
        "        if name == layer:\n",
        "            model_weights = param.tolist()\n",
        "    pretrained_model_weights = [] \n",
        "    for name, param in model_pretrained.named_parameters():\n",
        "        if name == layer:\n",
        "            pretrained_model_weights = param.tolist()\n",
        "    if spatial.distance.cosine(model_weights, pretrained_model_weights) == 0:\n",
        "        return 'no change'\n",
        "    else:\n",
        "        return 'change'"
      ],
      "metadata": {
        "id": "tiotAORu_WDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name + ': '+ changed_weight(name))"
      ],
      "metadata": {
        "id": "NbWjAXMX_Zso"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}